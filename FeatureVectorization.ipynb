{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "852cb561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from featureHelpers import process_dataframe\n",
    "import os\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec6944de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Found 100 CSV files\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e23a5134ad450a8ab60fceff89b6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing files:   0%|          | 0/100 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping (already exists): adoquin_atras_de_rectoria_frame_15.csv\n",
      "Skipping (already exists): adoquin_atras_de_rectoria_frame_2.csv\n",
      "Skipping (already exists): adoquin_atras_de_rectoria_frame_33.csv\n",
      "Skipping (already exists): adoquin_atras_de_rectoria_frame_46.csv\n",
      "Skipping (already exists): adoquin_atras_de_rectoria_frame_48.csv\n",
      "Skipping (already exists): adoquin_atras_de_rectoria_frame_54.csv\n",
      "Skipping (already exists): adoquin_atras_de_rectoria_frame_6.csv\n",
      "Skipping (already exists): adoquin_atras_de_rectoria_frame_61.csv\n",
      "Skipping (already exists): adoquin_atras_de_rectoria_frame_70.csv\n",
      "Skipping (already exists): adoquin_atras_de_rectoria_frame_72.csv\n",
      "Skipping (already exists): adoquin_cancha_de_futbol_10.csv\n",
      "Processing: adoquin_cancha_de_futbol_18.csv\n",
      "Processing 20,831 points with label 'adoquin'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5c23d8e07b483ebc2657de411683ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     df_features = \u001b[43mprocess_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m     successful += \u001b[32m1\u001b[39m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCompleted: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\PEF\\Terrain-Traversability-Analysis\\featureHelpers.py:128\u001b[39m, in \u001b[36mprocess_dataframe\u001b[39m\u001b[34m(df_path, output_path, classification_label)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# Process each point\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(n)):\n\u001b[32m    127\u001b[39m     \u001b[38;5;66;03m# Get neighbors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     neighbors_df = \u001b[43mknn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxyz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m     \u001b[38;5;66;03m# Compute features\u001b[39;00m\n\u001b[32m    131\u001b[39m     xnorms[i], ynorms[i], znorms[i] = estimate_normals(neighbors_df)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\PEF\\Terrain-Traversability-Analysis\\featureHelpers.py:21\u001b[39m, in \u001b[36mknn\u001b[39m\u001b[34m(xyz, index, df)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03mFind k nearest neighbors of a point within an XYZ array and return\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[33;03mthe corresponding rows from a Polars DataFrame.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m \u001b[33;03m    pl.DataFrame: Subset of `df` with the nearest neighbors to point `index`.\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     20\u001b[39m knn = NearestNeighbors(n_neighbors=\u001b[32m10\u001b[39m, algorithm=\u001b[33m'\u001b[39m\u001b[33mkd_tree\u001b[39m\u001b[33m'\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m).fit(xyz)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m distances, indexes = \u001b[43mknn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mxyz\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Polars allows indexing by row indices\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df[indexes[\u001b[32m0\u001b[39m]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:923\u001b[39m, in \u001b[36mKNeighborsMixin.kneighbors\u001b[39m\u001b[34m(self, X, n_neighbors, return_distance)\u001b[39m\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[32m    919\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    920\u001b[39m             \u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m does not work with sparse matrices. Densify the data, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    921\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mor set algorithm=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mbrute\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m % \u001b[38;5;28mself\u001b[39m._fit_method\n\u001b[32m    922\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m923\u001b[39m     chunked_results = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen_even_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    928\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33minternal: _fit_method not recognized\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:2070\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2064\u001b[39m \u001b[38;5;28mself\u001b[39m._call_ref = weakref.ref(output)\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2070\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1675\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1673\u001b[39m detach_generator_exit = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1674\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1675\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1676\u001b[39m     \u001b[38;5;66;03m# first yield returns None, for internal use only. This ensures\u001b[39;00m\n\u001b[32m   1677\u001b[39m     \u001b[38;5;66;03m# that we enter the try/except block and start dispatching the\u001b[39;00m\n\u001b[32m   1678\u001b[39m     \u001b[38;5;66;03m# tasks.\u001b[39;00m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1658\u001b[39m, in \u001b[36mParallel._start\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1649\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_start\u001b[39m(\u001b[38;5;28mself\u001b[39m, iterator, pre_dispatch):\n\u001b[32m   1650\u001b[39m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[32m   1651\u001b[39m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[32m   1657\u001b[39m     \u001b[38;5;28mself\u001b[39m._iterating = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1658\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1659\u001b[39m         \u001b[38;5;28mself\u001b[39m._iterating = \u001b[38;5;28mself\u001b[39m._original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1661\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dispatch_one_batch(iterator):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1540\u001b[39m, in \u001b[36mParallel.dispatch_one_batch\u001b[39m\u001b[34m(self, iterator)\u001b[39m\n\u001b[32m   1538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1539\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1437\u001b[39m, in \u001b[36mParallel._dispatch\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m   1430\u001b[39m \u001b[38;5;28mself\u001b[39m._register_new_job(batch_tracker)\n\u001b[32m   1432\u001b[39m \u001b[38;5;66;03m# If return_ordered is False, the batch_tracker is not stored in the\u001b[39;00m\n\u001b[32m   1433\u001b[39m \u001b[38;5;66;03m# jobs queue at the time of submission. Instead, it will be appended to\u001b[39;00m\n\u001b[32m   1434\u001b[39m \u001b[38;5;66;03m# the queue by itself as soon as the callback is triggered to be able\u001b[39;00m\n\u001b[32m   1435\u001b[39m \u001b[38;5;66;03m# to return the results in the order of completion.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1437\u001b[39m job = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1438\u001b[39m batch_tracker.register_job(job)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\_parallel_backends.py:339\u001b[39m, in \u001b[36mPoolManagerMixin.submit\u001b[39m\u001b[34m(self, func, callback)\u001b[39m\n\u001b[32m    335\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[32m    336\u001b[39m \u001b[38;5;66;03m# Here, we need a wrapper to avoid crashes on KeyboardInterruptErrors.\u001b[39;00m\n\u001b[32m    337\u001b[39m \u001b[38;5;66;03m# We also call the callback on error, to make sure the pool does not\u001b[39;00m\n\u001b[32m    338\u001b[39m \u001b[38;5;66;03m# wait on crashed jobs.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.apply_async(\n\u001b[32m    340\u001b[39m     _TracebackCapturingWrapper(func),\n\u001b[32m    341\u001b[39m     (),\n\u001b[32m    342\u001b[39m     callback=callback,\n\u001b[32m    343\u001b[39m     error_callback=callback,\n\u001b[32m    344\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\_parallel_backends.py:507\u001b[39m, in \u001b[36mThreadingBackend._get_pool\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    501\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Lazily initialize the thread pool\u001b[39;00m\n\u001b[32m    502\u001b[39m \n\u001b[32m    503\u001b[39m \u001b[33;03mThe actual pool of worker threads is only initialized at the first\u001b[39;00m\n\u001b[32m    504\u001b[39m \u001b[33;03mcall to apply_async.\u001b[39;00m\n\u001b[32m    505\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m     \u001b[38;5;28mself\u001b[39m._pool = \u001b[43mThreadPool\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_n_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\pool.py:930\u001b[39m, in \u001b[36mThreadPool.__init__\u001b[39m\u001b[34m(self, processes, initializer, initargs)\u001b[39m\n\u001b[32m    929\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, processes=\u001b[38;5;28;01mNone\u001b[39;00m, initializer=\u001b[38;5;28;01mNone\u001b[39;00m, initargs=()):\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m     \u001b[43mPool\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocesses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\pool.py:196\u001b[39m, in \u001b[36mPool.__init__\u001b[39m\u001b[34m(self, processes, initializer, initargs, maxtasksperchild, context)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;28mself\u001b[39m._taskqueue = queue.SimpleQueue()\n\u001b[32m    193\u001b[39m \u001b[38;5;66;03m# The _change_notifier queue exist to wake up self._handle_workers()\u001b[39;00m\n\u001b[32m    194\u001b[39m \u001b[38;5;66;03m# when the cache (self._cache) is empty or when there is a change in\u001b[39;00m\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# the _state variable of the thread that runs _handle_workers.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m \u001b[38;5;28mself\u001b[39m._change_notifier = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSimpleQueue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[38;5;28mself\u001b[39m._cache = _PoolCache(notifier=\u001b[38;5;28mself\u001b[39m._change_notifier)\n\u001b[32m    198\u001b[39m \u001b[38;5;28mself\u001b[39m._maxtasksperchild = maxtasksperchild\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\context.py:113\u001b[39m, in \u001b[36mBaseContext.SimpleQueue\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m'''Returns a queue object'''\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mqueues\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SimpleQueue\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSimpleQueue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\queues.py:360\u001b[39m, in \u001b[36mSimpleQueue.__init__\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *, ctx):\n\u001b[32m--> \u001b[39m\u001b[32m360\u001b[39m     \u001b[38;5;28mself\u001b[39m._reader, \u001b[38;5;28mself\u001b[39m._writer = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mduplex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    361\u001b[39m     \u001b[38;5;28mself\u001b[39m._rlock = ctx.Lock()\n\u001b[32m    362\u001b[39m     \u001b[38;5;28mself\u001b[39m._poll = \u001b[38;5;28mself\u001b[39m._reader.poll\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\connection.py:566\u001b[39m, in \u001b[36mPipe\u001b[39m\u001b[34m(duplex)\u001b[39m\n\u001b[32m    563\u001b[39m     access = _winapi.GENERIC_WRITE\n\u001b[32m    564\u001b[39m     obsize, ibsize = \u001b[32m0\u001b[39m, BUFSIZE\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m h1 = \u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCreateNamedPipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m    \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopenmode\u001b[49m\u001b[43m \u001b[49m\u001b[43m|\u001b[49m\u001b[43m \u001b[49m\u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFILE_FLAG_OVERLAPPED\u001b[49m\u001b[43m \u001b[49m\u001b[43m|\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFILE_FLAG_FIRST_PIPE_INSTANCE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE_TYPE_MESSAGE\u001b[49m\u001b[43m \u001b[49m\u001b[43m|\u001b[49m\u001b[43m \u001b[49m\u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE_READMODE_MESSAGE\u001b[49m\u001b[43m \u001b[49m\u001b[43m|\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE_WAIT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m    \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mibsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mNMPWAIT_WAIT_FOREVER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# default security descriptor: the handle cannot be inherited\u001b[39;49;00m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mNULL\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    575\u001b[39m h2 = _winapi.CreateFile(\n\u001b[32m    576\u001b[39m     address, access, \u001b[32m0\u001b[39m, _winapi.NULL, _winapi.OPEN_EXISTING,\n\u001b[32m    577\u001b[39m     _winapi.FILE_FLAG_OVERLAPPED, _winapi.NULL\n\u001b[32m    578\u001b[39m     )\n\u001b[32m    579\u001b[39m _winapi.SetNamedPipeHandleState(\n\u001b[32m    580\u001b[39m     h2, _winapi.PIPE_READMODE_MESSAGE, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    581\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "base_path = r'C:\\Users\\USER\\Downloads\\adoquin'\n",
    "output_base = r'C:\\Users\\USER\\PEF\\Terrain-Traversability-Analysis\\adoquin_features'\n",
    "class_label = 'adoquin'\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "# Get all CSV files\n",
    "csv_files = glob.glob(os.path.join(base_path, '**', '*.csv'), recursive=True)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"Found {len(csv_files)} CSV files\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Track progress and errors\n",
    "successful = 0\n",
    "failed = 0\n",
    "errors = []\n",
    "\n",
    "for csv_file in tqdm(csv_files, desc=\"Processing files\", unit=\"file\"):\n",
    "    filename = os.path.basename(csv_file)\n",
    "    \n",
    "    # Create output filename\n",
    "    output_filename = filename.replace('.csv', '_features.csv')\n",
    "    output_path = os.path.join(output_base, output_filename)\n",
    "    \n",
    "    # Skip if already processed\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"Skipping (already exists): {filename}\")\n",
    "        successful += 1\n",
    "        continue\n",
    "    \n",
    "    print(f\"Processing: {filename}\")\n",
    "    \n",
    "    try:\n",
    "        df_features = process_dataframe(csv_file, output_path, class_label)\n",
    "        successful += 1\n",
    "        print(f\"Completed: {filename}\")\n",
    "        \n",
    "        # Free memory after each file\n",
    "        del df_features\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        failed += 1\n",
    "        error_msg = f\"{filename}: {str(e)}\"\n",
    "        errors.append(error_msg)\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"All files processed!\")\n",
    "print(f\"Successful: {successful}/{len(csv_files)}\")\n",
    "print(f\"Failed: {failed}/{len(csv_files)}\")\n",
    "\n",
    "if errors:\n",
    "    print(\"\\nFailed files:\")\n",
    "    for error in errors:\n",
    "        print(f\"  - {error}\")\n",
    "        \n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save error log if any\n",
    "if errors:\n",
    "    error_log_path = os.path.join(output_base, 'processing_errors.txt')\n",
    "    with open(error_log_path, 'w') as f:\n",
    "        f.write(\"Processing Errors\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        for error in errors:\n",
    "            f.write(f\"{error}\\n\")\n",
    "    print(f\"\\nError log saved to: {error_log_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086901bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
